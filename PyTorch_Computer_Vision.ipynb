{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPAux06f2z1Cc1VyrcrfSUn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Computer Vision Libraries in Pytorch\n",
        "* `torchvision` - base domain library for Pytorch computer vision\n",
        "* `torchvision.dataset` - get datasets and data loading functions\n",
        "* `torchvision.models` - get pretrained computer vision models  \n",
        "* `torchvision.transforms` - functions for manipulating vision data (images) for use in ML model\n",
        "* `torch.utils.data.Dataset` - Base dataset class for Pytorch\n",
        "* `torch.utils.data.DataLoader` - Creates a Python iterable over a dataset"
      ],
      "metadata": {
        "id": "vQAwNtzE03q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib - visualize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check Versions\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "id": "jLuH6J7awldS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8B-rIspu8i5"
      },
      "outputs": [],
      "source": [
        "# Setup Device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the Dataset\n",
        "The dataset FashionMNIST from torchvision.datasets will be used."
      ],
      "metadata": {
        "id": "W0BpuHLI-YjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root = \"DATA\", # Root directory, where data will be saved\n",
        "    train = True, # Do we want training version of the data or testing version\n",
        "    download = True, # Download data\n",
        "    transform= torchvision.transforms.ToTensor(), # ToTensor(), how do we want to manipulate the data? Convert data into TENSORS\n",
        "    target_transform = None # How do we want to manipulate the labels/targets?\n",
        ")\n",
        "\n",
        "# Testing Data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root =\"DATA\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor(),\n",
        "    target_transform= None\n",
        ")"
      ],
      "metadata": {
        "id": "B3lfHGpuwwuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking Input & Output shapes of Data"
      ],
      "metadata": {
        "id": "ksabLnXXCRSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "fMPLfXDd_mBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image,label = train_data[0]\n",
        "image.shape, label"
      ],
      "metadata": {
        "id": "C_TPZlqT_5Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = train_data.classes\n",
        "class_name"
      ],
      "metadata": {
        "id": "dLk_TOUM_684"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a dictionary with class labels and index\n",
        "train_data.class_to_idx"
      ],
      "metadata": {
        "id": "yM6vIGtdAnHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Image Shape: {image.shape} -> [color_channels , width , height]\") # color_channels [0,1] because data is GREYSCALE so white may be 1 while black is 0 and grey inbetween\n",
        "print(f\"Label: {class_name[label]}\")"
      ],
      "metadata": {
        "id": "M9_p6UrlA_lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "r3pxkHvSFIM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the image"
      ],
      "metadata": {
        "id": "jUMeP3gEB6Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Image Shape: {image.shape}\") # (C,W,H)\n",
        "plt.title(f\"Label: 9 // {class_name[label]}\")\n",
        "plt.axis(\"off\") # Removes axis of main\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(f\"torch.permute()\")\n",
        "image = image.permute(1,2,0) # Matplotlib expects (Weidth,Height) or (W,H,C) so permute can help dimensionality permutation (alteration)\n",
        "print(f\"Image Shape after permuation: {image.shape}\")\n",
        "plt.imshow(image, cmap = \"gray\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(\"torch.squeeze()\") # Returns a tensor with all specified dimensions of input of size 1 removed\n",
        "plt.imshow(image.squeeze(),cmap = \"gray\")\n",
        "plt.plot()\n",
        "image = image.permute(2,0,1) # permute() is a view of the original tensor hence change back to original shape\n",
        "print(f\"Image Shape after reversing permuation: {image.shape}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HLqIiV-cDMyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot more Images\n",
        "torch.manual_seed(42)\n",
        "row,col = 4,4\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.3) # Provide some spacing between subplots\n",
        "\n",
        "for i in range(1,row*col+1):\n",
        "  random_idx = torch.randint(0,len(train_data),size=[1]).item()\n",
        "  # print(random_idx)\n",
        "  image,label = train_data[random_idx]\n",
        "  plt.subplot(row,col,i)\n",
        "  plt.title(f\"{class_name[label]}\")\n",
        "  plt.axis(False) # Turn Off Axis\n",
        "  plt.imshow(image.squeeze(),cmap=\"gray\")"
      ],
      "metadata": {
        "id": "07E7s49-DYau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataloader\n",
        "* Dataloader turns dataset into Python iterable.\n",
        "* More specifically, we want to turn our data into batches or minibatches.\n",
        "\n",
        "Why do this?\n",
        "1. It is more computationally efficient, computer hardware may not be able to look at 60000 images all at once (store in memory). So we break it down to 32 images at a time (batch size of 32)\n",
        "2. It gives out neural network more chances to update its gradients per batch."
      ],
      "metadata": {
        "id": "olFop3vWIczN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader = DataLoader(\n",
        "    dataset = train_data,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True # Make the batch size consist of random samples from the dataset\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    dataset = test_data,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "8R1WYv-XLN5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check out what we have created\n",
        "print(f\"Train Dataloader: {train_dataloader}\")\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"\\nTest Dataloader: {train_dataloader}\")\n",
        "print(f\"Length of test dataloader: {len(test_dataloader)} Batches of {BATCH_SIZE}\")"
      ],
      "metadata": {
        "id": "OeGudhdxOfhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize what's inside a Batch\n",
        "train_feature_batch, train_label_batch = next(iter(train_dataloader))\n",
        "train_feature_batch.shape, train_label_batch.shape"
      ],
      "metadata": {
        "id": "ol6LF9U7O8fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `train_dataloader`: In PyTorch, a `DataLoader` is an iterable that provides batches of data. Each iteration returns a batch containing input data (e.g., images or features) and corresponding labels.\n",
        "\n",
        "* `iter(train_dataloader)`: Converts the `DataLoader` object into an iterator, allowing you to manually fetch batches.\n",
        "\n",
        "* `next(...)`: Fetches the first batch from the `train_dataloader` iterator."
      ],
      "metadata": {
        "id": "9eeNWGrqQ9qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_idx = torch.randint(0,len(train_feature_batch),size = [1]).item()\n",
        "img,label = train_feature_batch[random_idx],train_label_batch[random_idx]\n",
        "plt.title(f\"{class_name[label]}\")\n",
        "plt.axis(False)\n",
        "plt.imshow(img.squeeze(),cmap=\"gray\")\n",
        "plt.plot()\n",
        "print(f\"Image Shape: {img.shape}\")\n",
        "print(f\"Label: {label}, {label.shape}\")"
      ],
      "metadata": {
        "id": "SOFzXrp5QoJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flatten Layer\n",
        "* 1 value per pixel"
      ],
      "metadata": {
        "id": "4CcbaFfMQ8zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape before flattening: {train_feature_batch[0].shape}\")\n",
        "flatten_layer = nn.Flatten()\n",
        "print(f\"Shape after flattening: {flatten_layer(train_feature_batch[0]).shape}\") # 28*28 = 783 -> 1 value per pixel -> batch_size, [channels * height * width]\n",
        "# Flatten the image to pass it as a single vector to the model"
      ],
      "metadata": {
        "id": "YmgiIS83mWUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Helper Functions"
      ],
      "metadata": {
        "id": "xkutUJDWmiLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"File Already Exists\")\n",
        "else:\n",
        "  print(\"Downloading Helper Functions\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/refs/heads/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\",\"wb\") as f:\n",
        "    f.write(request.content)\n",
        "\n",
        "import helper_functions\n",
        "from helper_functions import accuracy_fn"
      ],
      "metadata": {
        "id": "vN1U_fmMrpwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a time function\n",
        "\n",
        "Machine learning is very experimental.\n",
        "\n",
        "It is important to keep track of two things.\n",
        "1. Model's performance (Loss / Accuracy Metrics)\n",
        "2. Time (How fast it runs)"
      ],
      "metadata": {
        "id": "xT0MM9Rtttvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "  \"\"\" Prints device and time difference between start and end times\n",
        "  Args:\n",
        "  start (float): Starting time of computation - preferred in timeit format\n",
        "  end (float): End time of computation\n",
        "  device([type], optional): Device on which model is running, default is None\n",
        "\n",
        "  Returns:\n",
        "  float: time between start and end in seconds (higher is longer)\n",
        "  \"\"\"\n",
        "\n",
        "  total_time = end - start\n",
        "  print(f\"Train Time on Device {device}: {total_time:.3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "07074zncsjU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Model\n",
        "* It is good practice to create a base model when experimenting.\n",
        "* The base model can then be modified to make it a better fit for our dataset./\n"
      ],
      "metadata": {
        "id": "nnHIhit6jATQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_V0 = nn.Sequential(\n",
        "    nn.Flatten(), # Because we've now turned our pixel data from height and width dimensions into one long feature vector.\n",
        "    nn.Linear(in_features=784,out_features=16), # 784 output from Flatten layer [color_channels, height*width]\n",
        "    nn.Linear(in_features = 16, out_features = len(class_name)) # 10 as in 10 labels from class_name\n",
        ")\n",
        "model_V0"
      ],
      "metadata": {
        "id": "-OzKTQmNw6hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(class_name),len(class_name),class_name"
      ],
      "metadata": {
        "id": "27GRjt5jxpCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Loss and Optimizer"
      ],
      "metadata": {
        "id": "Z4ks9i2DyNQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = model_V0.parameters(),lr = 0.1)"
      ],
      "metadata": {
        "id": "EusD8NRqcqHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing Loop\n",
        "* Loop through Epochs\n",
        "* Loop through Training batches, perform steps, calulating train loss per batch\n",
        "* Loop through Testing batches, perform steps, calculating test loss per batch\n",
        "* Print what's happening\n",
        "* Time it out"
      ],
      "metadata": {
        "id": "qJAwA66Vc-Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data),len(train_dataloader.dataset),len(train_dataloader)"
      ],
      "metadata": {
        "id": "wyqto2zBhg5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a progress bar\n",
        "from tqdm.auto import tqdm # Progress bar\n",
        "\n",
        "# Random Seed & Start Timer\n",
        "torch.manual_seed(42)\n",
        "train_time_start_cpu = timer()\n",
        "\n",
        "# Set the number of epochs (we'll keep this small for faster training times)\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n------\")\n",
        "  train_loss = 0\n",
        "  for batch, (X,y) in enumerate(train_dataloader):\n",
        "    # Training Mode\n",
        "    model_V0.train()\n",
        "    # 1. Forward Pass\n",
        "    y_preds = model_V0(X)\n",
        "    # 2. Calculate Loss (Per Batch)\n",
        "    loss = loss_fn(y_preds,y)\n",
        "    train_loss += loss # accumulatively add up loss per epoch\n",
        "    # 4. Optimizer Zero Grad\n",
        "    optimizer.zero_grad()\n",
        "    # 5. Loss Backward (Backpropagation)\n",
        "    loss.backward()\n",
        "    # 6. Optimizer Step (Gradient Descent)\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out how many samples have been seen\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Number of Samples: {batch * len(X)} / {len(train_dataloader.dataset)}\")\n",
        "\n",
        "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "  train_loss /= len(train_dataloader)\n",
        "\n",
        "  # Testing\n",
        "  model_V0.eval()\n",
        "  test_loss, test_acc = 0,0\n",
        "  with torch.inference_mode():\n",
        "    for X,y in test_dataloader:\n",
        "      # 1. Forward Pass\n",
        "      test_preds = model_V0(X)\n",
        "      # 2. Calculate Loss (accumulatively)\n",
        "      test_loss += loss_fn(test_preds,y) # accumulatively add up the loss per epoch\n",
        "      # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "      test_acc += accuracy_fn(y_true=y,y_pred = test_preds.argmax(dim=1))\n",
        "\n",
        "   # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "   # Divide total test loss by length of test dataloader (per batch)\n",
        "    test_loss /= len(test_dataloader)\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  ## Print out what's happening\n",
        "  print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
        "\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_cpu,\n",
        "                                           end=train_time_end_on_cpu,\n",
        "                                           device=str(next(model_V0.parameters()).device))\n",
        "\n"
      ],
      "metadata": {
        "id": "VZwJsM-ldXYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make predictions\n",
        "* Create a function such that later on, different models can be compared."
      ],
      "metadata": {
        "id": "eDJ1cE57gqGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Random Seed\n",
        "torch.manual_seed(42)\n",
        "def eval_mode(model: torch.nn.Module,\n",
        "              model_name: str,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "  \"\"\"Returns:\n",
        "  A dictionary containing Model metrics based on predictions made.\n",
        "  \"\"\"\n",
        "  loss,acc = 0,0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X,y in tqdm(data_loader):\n",
        "      # Put Data on target device\n",
        "      X,y = X.to(device),y.to(device)\n",
        "      # Make Predictions (Forward Pass)\n",
        "      y_preds = model(X)\n",
        "      # Calculate Loss/Accuracy\n",
        "      loss += loss_fn(y_preds,y) # Accumulated Loss per Batch\n",
        "      acc += accuracy_fn(y_true = y, y_pred = y_preds.argmax(dim=1)) # Accumulated Accuracy per Batch\n",
        "\n",
        "    loss /= len(data_loader) # Avg Loss per Batch\n",
        "    acc /= len(data_loader) # Avg Accuracy per Batch\n",
        "\n",
        "  return {\"Model_Name\": model_name,\n",
        "          \"Model_Loss\" : loss.item(),\n",
        "          \"Model_Accuracy\" : acc}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "raqhTLMFYCtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_V0_results = eval_mode(model = model_V0,\n",
        "                             model_name=\"model_V0\",\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn = loss_fn,\n",
        "                             accuracy_fn=accuracy_fn,\n",
        "                             device = \"cpu\")\n",
        "model_V0_results"
      ],
      "metadata": {
        "id": "EpuEXRR1aXnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Model on GPU (Device Agnostic)"
      ],
      "metadata": {
        "id": "9a_DrS3JdCLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "zESPSq0URqEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "0UkyZtCHQ647"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_V1 = nn.Sequential(nn.Flatten(),\n",
        "                         nn.Linear(in_features=784, out_features = 16),\n",
        "                         nn.ReLU(),\n",
        "                         nn.Linear(in_features =16, out_features=len(class_name)),\n",
        "                         nn.ReLU()\n",
        "                         ).to(device)\n",
        "model_V1,next(model_V1.parameters()).device"
      ],
      "metadata": {
        "id": "zunwqGHiRYAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function & Optimizer\n"
      ],
      "metadata": {
        "id": "BGdzy5q_Sg8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(lr = 0.1,params = model_V1.parameters())"
      ],
      "metadata": {
        "id": "S-Xq-pTSTlvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Function"
      ],
      "metadata": {
        "id": "W1a9C-zYTwnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device = device):\n",
        "  \"\"\"Training Function: Includes all the code for training loop\"\"\"\n",
        "  # Training\n",
        "  train_loss, train_acc = 0,0\n",
        "  # Train mode\n",
        "  model.train()\n",
        "\n",
        "  # Training Loop to loop through training batches\n",
        "  for batch, (X,y) in enumerate(data_loader):\n",
        "    # Put Data on target Device\n",
        "    X,y = X.to(device), y.to(device)\n",
        "    # 1. Forward Pass\n",
        "    train_preds = model(X)\n",
        "    # 2. Calculate Loss (per batch) // Accuracy\n",
        "    loss = loss_fn(train_preds,y)\n",
        "    train_loss += loss # Accumulate train Loss\n",
        "    train_acc += accuracy_fn(y_true = y, y_pred = train_preds.argmax(dim=1)) # Logits to Prediction Labels\n",
        "\n",
        "    # 3. Optimizer Zero Grad\n",
        "    optimizer.zero_grad()\n",
        "    # 4. Loss Back propagation\n",
        "    loss.backward()\n",
        "    # 5. Optimizer Step (Update the model's parameters once *per batch*)\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  # Print out what's happening\n",
        "  print(f\"Train Loss: {train_loss:.5f} | Train Accuracy: {train_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "J3fpgYu3UgR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Function"
      ],
      "metadata": {
        "id": "ceUsJuregBVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              data_loader:torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "  \"\"\"Performs a testing loop step on model going over data_loader.\"\"\"\n",
        "  # Instantiate loss and accuracy values\n",
        "  test_loss,test_acc = 0,0\n",
        "  # Eval mode\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "      # Put data on target Device\n",
        "      X,y = X.to(device), y.to(device)\n",
        "      # 1. Forward pass (outputs raw logits)\n",
        "      test_preds = model(X)\n",
        "      # 2. Calculate Loss\n",
        "      test_loss += loss_fn(test_preds,y)\n",
        "      # 3. Calculate Accuracy\n",
        "      test_acc += accuracy_fn(y_true = y, y_pred = test_preds.argmax(dim=1)) # Logits to Prediction Labels\n",
        "\n",
        "    # Inside torch.inference_mode(), Get Avg Loss, Accuracy\n",
        "    test_loss /= len(data_loader)\n",
        "    test_acc /= len(data_loader)\n",
        "    print(f\"Test Loss: {test_loss:.5f} | Test Accuracy: {test_acc:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "kNKZTEgggDmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = model_V1.parameters(),lr = 0.1)\n",
        "# Progress Bar\n",
        "from tqdm.auto import tqdm\n",
        "# Random Seed\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "# Timer Start\n",
        "timer_start_gpu = timer()\n",
        "# Number of Epochs\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n----\")\n",
        "  train_step(model = model_V1,\n",
        "             data_loader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             optimizer = optimizer)\n",
        "  test_step(model = model_V1,\n",
        "            data_loader= test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            accuracy_fn=accuracy_fn)\n",
        "\n",
        "timer_end_gpu = timer()\n",
        "total_train_time_model_1 = print_train_time(start=timer_start_gpu,\n",
        "                                           end=timer_end_gpu,\n",
        "                                           device=str(next(model_V1.parameters()).device))\n",
        "\n"
      ],
      "metadata": {
        "id": "1XPCH1HCisp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Sometimes, depending on the data/hardware, the model may train faster on CPU than GPU.\n",
        "\n",
        "1. It could be that the overhead for copying data/model to and from the GPU outweighs the compute benefits offered by the GPU.\n",
        "2. The hardware that is being used has a better CPU in terms of compute capability than the GPU."
      ],
      "metadata": {
        "id": "U5giHMihmMCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_train_time_model_0,total_train_time_model_1"
      ],
      "metadata": {
        "id": "5-nfdPRel4xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_V1_results = eval_mode(model = model_V1,\n",
        "                             model_name=\"model_V1_Non_Linear\",\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn = loss_fn,\n",
        "                             accuracy_fn=accuracy_fn)\n",
        "model_V0_results,model_V1_results"
      ],
      "metadata": {
        "id": "49JLwnXBmwxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: CNN\n",
        "\n",
        "* CNN are also known as ConvNets.\n",
        "* CNNs (Convolutional Neural Networks) are known for their capabilities to find patterns within visual data.\n",
        "* To learn, what's happening inside a CNN, check out this website: https://poloclub.github.io/cnn-explainer/"
      ],
      "metadata": {
        "id": "CZDXMPoOnNZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvModel(nn.Module):\n",
        "  \"\"\"\n",
        "  Model Architecture that resembles that TinyVGG model fron CNN Explainer Website\n",
        "  \"\"\"\n",
        "  def __init__(self,input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = input_shape,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3, # ---- Hyperparameters ----\n",
        "                  padding = 1,\n",
        "                  stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2 # Max pooling outputs the max value from the input window given\n",
        "                     )\n",
        "\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7, # Trick: Print the shapes of previous layers and find out the corresponding value\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "      x = self.conv_block_1(x)\n",
        "      #print(f\"Output Shape of ConvBlock1: {x.shape}\")\n",
        "      x = self.conv_block_2(x)\n",
        "      #print(f\"Output Shape of ConvBlock2: {x.shape}\")\n",
        "      x = self.classifier(x)\n",
        "      #print(f\"Output Shape of Classifier: {x.shape}\")\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "Pz4MKO54Bqbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Instance of Model\n",
        "torch.manual_seed(42)\n",
        "model_V2 = ConvModel(input_shape = 1,\n",
        "                     hidden_units = 10,\n",
        "                     output_shape = len(class_name)).to(device)\n",
        "model_V2"
      ],
      "metadata": {
        "id": "c6RVjgmoJhkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Loss Function & Optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params= model_V2.parameters(),lr = 0.01)\n",
        "# Progress Bar\n",
        "from tqdm.auto import tqdm\n",
        "# Random Seed\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "# Timer Start\n",
        "timer_start_gpu = timer()\n",
        "# Number of Epochs\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-----\")\n",
        "  train_step(model = model_V2,\n",
        "             data_loader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             optimizer = optimizer)\n",
        "  test_step(model = model_V2,\n",
        "            data_loader= test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            accuracy_fn=accuracy_fn)\n",
        "\n",
        "timer_end_gpu = timer()\n",
        "total_train_time_model_2 = print_train_time(start=timer_start_gpu,\n",
        "                                           end=timer_end_gpu,\n",
        "                                           device=str(next(model_V2.parameters()).device))\n",
        "\n"
      ],
      "metadata": {
        "id": "-UHX41jPEAgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_V2_results = eval_mode(model = model_V2,\n",
        "                             model_name=\"model_V2_ConV\",\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn = loss_fn,\n",
        "                             accuracy_fn=accuracy_fn)"
      ],
      "metadata": {
        "id": "EUbd6qYlERHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_V2_results"
      ],
      "metadata": {
        "id": "C8u5TTcJF5Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_V0_results,model_V1_results,model_V2_results]) # pass the dictionaries as list\n",
        "compare_results"
      ],
      "metadata": {
        "id": "wJIko2qKF7eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add training time to the table"
      ],
      "metadata": {
        "id": "35XyUMIBKkH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_train_time_model_0,total_train_time_model_1,total_train_time_model_2"
      ],
      "metadata": {
        "id": "b3iwsNB9IHsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_results [\"Training Time\"] = [total_train_time_model_0,total_train_time_model_1,total_train_time_model_2]\n",
        "compare_results"
      ],
      "metadata": {
        "id": "aHSYIf0lKKRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize our model\n",
        "compare_results.set_index(\"Model_Name\")[\"Model_Accuracy\"].plot(kind=\"barh\")\n",
        "plt.xlabel(\"Accuracy (%)\")\n",
        "plt.ylabel(\"Model\")\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "UFKs21N3Kghx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make random predictions and Visualize\n"
      ],
      "metadata": {
        "id": "goKaVLxfLpxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(model: torch.nn.Module,\n",
        "                    data: list,\n",
        "                    device: torch.device = device):\n",
        "  pred_probs = []\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      # Get sample on device\n",
        "      sample = torch.unsqueeze(sample, dim = 0).to(device)\n",
        "      # Logits\n",
        "      pred_logit = model(sample)\n",
        "      # Logits -> Pred Probs\n",
        "      pred_prob = torch.softmax(pred_logit.squeeze(),dim=0)\n",
        "      # Get Pred Prob off GPU for further calculations\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "  # Stack Pred_Probs to turn list into tensor\n",
        "  return torch.stack(pred_probs)"
      ],
      "metadata": {
        "id": "iSq6k8OONpRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "#random.seed(42)\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data),k = 9):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "test_samples[0].shape"
      ],
      "metadata": {
        "id": "XNkTLKM4O4b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_samples[0].squeeze(),cmap=\"gray\")\n",
        "plt.title(class_name[test_labels[0]])"
      ],
      "metadata": {
        "id": "qLXUAL21QXV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making Predictions\n",
        "pred_probs = make_prediction(model = model_V2,\n",
        "                             data = test_samples)\n",
        "# View first 2 prediction probabilities\n",
        "pred_probs[:2]"
      ],
      "metadata": {
        "id": "1GdRKdebQerS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conver prediction probabilities to labels\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ],
      "metadata": {
        "id": "9amGOpSERaXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "id": "cX0L6GcNSAQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize\n",
        "plt.figure(figsize=(9,9))\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "#plt.subplots_adjust(wspace=1, hspace=0.3) # Provide some spacing between subplots\n",
        "for i, sample in enumerate(test_samples):\n",
        "  # Subplot\n",
        "  plt.axis(False)\n",
        "  plt.subplot(nrows,ncols,i+1) # i starts from 0\n",
        "  # Plot image\n",
        "  plt.imshow(test_samples[i].squeeze())\n",
        "  # Get predictions labels\n",
        "  prd = class_name[pred_classes[i]]\n",
        "  # Get True labels\n",
        "  tru = class_name[test_labels[i]]\n",
        "  if prd == tru:\n",
        "    plt.title(f\"Pred: {prd} | Truth: {tru}\", c = \"g\", fontsize = 10)\n",
        "  else:\n",
        "    plt.title(f\"Pred: {prd} | Truth: {tru}\", c = \"r\", fontsize = 10)"
      ],
      "metadata": {
        "id": "xgy6Zw43SE35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making a confusion Matrix for further performance evaluation\n",
        "A confusion matrix is an excellent way of evaluating your classification model.\n",
        "1. Using our trained model, make predictions on test dataset.\n",
        "2. Make a confusion matrix `torchmetrics.ConfusionMatrix`\n",
        "3. Visualize the confusion matrix using `mlxtend.plotting.plot_confusion_matrix()`"
      ],
      "metadata": {
        "id": "xDyBgzZ_Vlor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlxtend\n",
        "mlxtend.__version__"
      ],
      "metadata": {
        "id": "_MllBVVLZ_IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Make predictions\n",
        "pred_probs = []\n",
        "model_V2.eval()\n",
        "with torch.inference_mode():\n",
        "  for X,y in tqdm(test_dataloader, desc = \"Making Predictions....\"):\n",
        "    # Send data and targets to device\n",
        "    X,y = X.to(device),y.to(device)\n",
        "    # Forward Pass\n",
        "    y_logit = model_V2(X)\n",
        "    # Logits to Predictions to Labels\n",
        "    y_pred = torch.softmax(y_logit.squeeze(), dim = 0).argmax(dim=1)\n",
        "    # Put the labels on cpu\n",
        "    pred_probs.append(y_pred.cpu())\n",
        "\n",
        "# Concatenate list to turn into tensor\n",
        "pred_tensor = torch.cat(pred_probs)\n",
        "pred_tensor\n",
        "\n"
      ],
      "metadata": {
        "id": "bg2MEG7MaGkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pred_tensor)"
      ],
      "metadata": {
        "id": "ByhUvIoVdTpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See if packages are installed otherwise, install them\n",
        "try:\n",
        "  import torchmetrics,mlxtend\n",
        "  print(\"Libraries Already EXIST\")\n",
        "  print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "  print(f\"torchmetrics version: {torchmetrics.__version__}\")\n",
        "  assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend version should be 0.19\"\n",
        "except:\n",
        "  !pip install -q torchmetrics -U mlxtend\n",
        "  import torchmetrics,mlxtend\n",
        "  print(\"Libraries INSTALLING...\")\n",
        "  print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "  print(f\"torchmetrics version: {torchmetrics.__version__}\")\n"
      ],
      "metadata": {
        "id": "aePG0ozHedCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int(mlxtend.__version__.split(\".\")[1])"
      ],
      "metadata": {
        "id": "Qg2X-ICEeu8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_tensor,test_data.targets,test_data.classes"
      ],
      "metadata": {
        "id": "vYV2imzHIhxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# 2. Setup confusion instance and compare predictions to targets\n",
        "confmat = ConfusionMatrix(num_classes = len(class_name), task = \"multiclass\")\n",
        "confmat_tensor = confmat(preds = pred_tensor, target = test_data.targets)\n",
        "\n",
        "# 3. Plot the Confusion Matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat = confmat_tensor.numpy(), #matplotlib likes working with numpy\n",
        "                                class_names = class_name,\n",
        "                                figsize=(10,7)\n",
        "                                ) # Darker Boxes along the diagonal is a good sign # Ideal Confusion matrix has only the diagonal line as darkened"
      ],
      "metadata": {
        "id": "o16fTAK7f2qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving & Loading Our Best Model"
      ],
      "metadata": {
        "id": "Qa4hxLgOIXPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "# Create Directory\n",
        "model_path = Path(\"model\")\n",
        "model_path.mkdir(parents=True,exist_ok=True)\n",
        "\n",
        "# Model Save Path\n",
        "model_name = \"model_V2_ConV.pth\"\n",
        "model_save_path = model_path / model_name\n",
        "\n",
        "# Save model\n",
        "torch.save(obj = model_V2.state_dict(), f = model_save_path)\n",
        "print(f\"Model Saved to: {model_save_path}\")"
      ],
      "metadata": {
        "id": "mKv6WjU3I15j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model\n",
        "torch.manual_seed(42)\n",
        "model_3 = ConvModel(input_shape = 1,\n",
        "                    hidden_units=10,\n",
        "                    output_shape=len(class_name)).to(device)\n",
        "model_3.load_state_dict(torch.load(f = model_save_path))\n"
      ],
      "metadata": {
        "id": "yiORR_A6L58-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "torch.manual_seed(42)\n",
        "model_3_results = eval_mode(model = model_3,\n",
        "                            model_name = \"LOADED MODEL\",\n",
        "                            data_loader = test_dataloader,\n",
        "                            loss_fn = loss_fn,\n",
        "                            accuracy_fn = accuracy_fn)\n",
        "model_3_results,model_V2_results"
      ],
      "metadata": {
        "id": "9poHf3CCM6P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if model results are close to eachother\n",
        "torch.isclose(torch.tensor(model_3_results[\"Model_Loss\"]),\n",
        "              torch.tensor(model_V2_results[\"Model_Loss\"]),\n",
        "              )"
      ],
      "metadata": {
        "id": "2jkAnSX1NsZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises"
      ],
      "metadata": {
        "id": "gkNilbHHOvg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "e-n4UamsQalq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Manufacturing (Quality Control & Defect Detection)\n",
        "* Autonomous Vehicles (Lane Recognition & Obstacle Detection)\n",
        "* Healthcare (Medical Image Analysis)"
      ],
      "metadata": {
        "id": "P1w7EuCRQeCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "WKeEfz0hQhCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting occurs when the model learns the training dataset too well, along with its noises and redundant features. Then, it underperforms in predicting new data."
      ],
      "metadata": {
        "id": "4tVxH7SKQurt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. Note: there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "fxXvhY0aQoPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Use more data such that the model can train better.\n",
        "* Use L1 or L2 regularization, adds a penalty term to the loss function to discourage large weights\n",
        "* Use data augmentation (create artificial data based on training set)\n",
        "* Use simpler data models\n",
        "* Spliting the dataset into training, validation, testing datasets.\n",
        "* Early stopping, stops the model training before it learns the noise within the data."
      ],
      "metadata": {
        "id": "9k_i3LPVQvSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Spend 20-minutes reading and clicking through the CNN Explainer website.\n",
        "Upload your own example image using the \"upload\" button and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "ddEkmt6PQwFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Load the torchvision.datasets.MNIST() train and test datasets."
      ],
      "metadata": {
        "id": "bgSL7HYMQ1NH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root = \"traindata\",\n",
        "                                        train = True,\n",
        "                                        target_transform=None,\n",
        "                                        download = True,\n",
        "                                        transform = ToTensor()\n",
        "\n",
        "                                        )\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root = \"testdata\",\n",
        "                                       train = False,\n",
        "                                       download = True,\n",
        "                                       transform = ToTensor()) # Data comes in as PIL format, ToTensor() transforms it into tensor"
      ],
      "metadata": {
        "id": "xSnQXhHjQ7Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "1Y_OjI3oQ8Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RAZMqnrTX4J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = train_data[0][0].squeeze()\n",
        "plt.imshow(img,cmap=\"gray\")\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "xQg11i6gXzM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "btbKhFuTcnXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "nrows = 1\n",
        "ncols = 5\n",
        "for i in range(0,nrows*ncols):\n",
        "  random_idx = torch.randint(0,len(train_data),size=[1]).item()\n",
        "  img , label = train_data[random_idx]\n",
        "  plt.subplot(nrows,ncols,i+1)\n",
        "  plt.axis(False)\n",
        "  plt.imshow(img.squeeze(),cmap=\"gray\")\n",
        "  plt.title(class_names[label])"
      ],
      "metadata": {
        "id": "cNLftMzzRHaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Turn the MNIST train and test datasets into dataloaders using torch.utils.data.DataLoader, set the batch_size=32."
      ],
      "metadata": {
        "id": "vZgBNqwyQ725"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_DL = DataLoader(dataset = train_data,batch_size = 32,shuffle = True )\n",
        "test_DL = DataLoader(dataset = test_data, batch_size = 32, shuffle = False)"
      ],
      "metadata": {
        "id": "GJl8QKUFRH-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Recreate model_2 used in this notebook (the same model from the CNN Explainer website, also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "ZzS130pgRIvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_f, train_L = next(iter(train_DL))\n",
        "train_f.shape,train_L.shape"
      ],
      "metadata": {
        "id": "vddzTqqUgs4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class TINYVGG(nn.Module):\n",
        "  def __init__(self,input_shape,output_shape,hidden_units):\n",
        "    super().__init__()\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,out_channels=hidden_units,kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = hidden_units, out_channels=hidden_units,kernel_size = 3, stride = 1, padding =1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = hidden_units, out_channels=hidden_units,kernel_size = 3, stride = 1, padding =1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = hidden_units*7*7, # nn.Flatten Gives out [1,784] size. hence to Make 784 -> 16*7*7\n",
        "                  out_features = output_shape))\n",
        "  def forward(self,x):\n",
        "    x = self.block_1(x)\n",
        "    #print(f\"Block 1 Output Shape: {x.shape}\")\n",
        "    x = self.block_2(x)\n",
        "    #print(f\"Block 2 Output Shape: {x.shape}\")\n",
        "    x = self.classifier(x)\n",
        "    #print(f\"Classifier Output Shape: {x.shape}\")\n",
        "    return x\n",
        "\n",
        "\n",
        "# Create model instance\n",
        "torch.manual_seed(42)\n",
        "model = TINYVGG(\n",
        "    input_shape = 1, # 1 Image\n",
        "    hidden_units = 16,\n",
        "    output_shape= len(class_names)\n",
        ")\n",
        "model"
      ],
      "metadata": {
        "id": "Iq_k5I9MROE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0][0].shape,len(class_names)"
      ],
      "metadata": {
        "id": "LfJjqiQFf8KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten  = nn.Flatten()\n",
        "img = flatten(train_data[0][0])\n",
        "img.shape"
      ],
      "metadata": {
        "id": "5-JWn73IkQaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.rand(size=(1,28,28))"
      ],
      "metadata": {
        "id": "2qQIcNxxlKUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(img.unsqueeze(0))"
      ],
      "metadata": {
        "id": "WhDOcEQlhx43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Train the model you built in exercise 8. on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "Ex9T7vSRRP22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "if Path(\"helper_function.py\").is_file():\n",
        "  print(\"...File Exists Already...\")\n",
        "else:\n",
        "  print(\"...Downloading FILE...\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/refs/heads/main/helper_functions.py\")\n",
        "  with open(\"helper_function.py\",\"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "6QUEgqXVo3op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import helper_function\n",
        "from helper_function import accuracy_fn\n",
        "from timeit import default_timer as timer"
      ],
      "metadata": {
        "id": "RiLu9nOVpcao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)\n",
        "# Training Loop\n",
        "def Training(model: nn.Module,\n",
        "             data: torch.utils.data.DataLoader,\n",
        "             device: torch.device):\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  for X,y in data:\n",
        "    X,y = X.to(device),y.to(device)\n",
        "    # Forward Pass\n",
        "    y_logits = model(X)\n",
        "    # Calculate Loss\n",
        "    loss = loss_fn(y_logits,y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_pred=y_logits.argmax(dim=1),y_true=y)\n",
        "    # Optimizer Zero Grad\n",
        "    optimizer.zero_grad()\n",
        "    # Loss Backward\n",
        "    loss.backward()\n",
        "    # Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(data)\n",
        "  train_acc /= len(data)\n",
        "  print(f\"Train Loss: {train_loss} | Train Accuracy: {train_acc:.3f}%\")\n",
        "\n",
        "def testing(model: nn.Module,\n",
        "             data: torch.utils.data.DataLoader,\n",
        "             device: torch.device):\n",
        "  model.to(device)\n",
        "  test_loss = 0\n",
        "  test_acc = 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X,y in data:\n",
        "      X,y = X.to(device),y.to(device)\n",
        "      test_logits = model(X)\n",
        "      test_loss += loss_fn(test_logits,y)\n",
        "      test_acc += accuracy_fn(y_true = y, y_pred = test_logits.argmax(dim=1))\n",
        "\n",
        "    test_loss /= len(data)\n",
        "    test_acc /= len(data)\n",
        "    print(f\"Test Loss: {test_loss} | Test Accuracy: {test_acc:.3f}%\")\n",
        "\n",
        "def time(start,end,device):\n",
        "  total = end - start\n",
        "  print(f\"Total Time on {device} is {total} seconds...\")\n",
        "  return total\n"
      ],
      "metadata": {
        "id": "AYbqIALMRVAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "epochs = 3\n",
        "start_time = timer()\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n------\")\n",
        "  Training(model=model,data=train_DL,device=\"cpu\")\n",
        "  testing(model=model,data=test_DL,device=\"cpu\")\n",
        "end_time = timer()\n",
        "time_cpu=time(start=start_time,end=end_time,device=\"cpu\")\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n------\")\n",
        "  Training(model=model,data=train_DL,device=\"cuda\")\n",
        "  testing(model=model,data=test_DL,device=\"cuda\")\n",
        "end_time = timer()\n",
        "time_gpu=time(start=start_time,end=end_time,device=\"cuda\")"
      ],
      "metadata": {
        "id": "_LB6ekh5smxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediction to the target label."
      ],
      "metadata": {
        "id": "h9H1I3FHRXuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "random.seed(100)\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "\n",
        "for samples,labels in random.sample(list(test_data),k=5):\n",
        "  test_samples.append(samples)\n",
        "  test_labels.append(labels)\n",
        "\n",
        "len(test_samples),test_samples[0].shape,class_names[test_labels[0]]"
      ],
      "metadata": {
        "id": "bchnXlxiyG8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cuda\")\n",
        "pred_prob = []\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  for sample in test_samples:\n",
        "    sample = sample.to(\"cuda\")\n",
        "    sample = sample.unsqueeze(dim=0) # Add batch dimension for model\n",
        "    logit = model(sample)\n",
        "    label = torch.softmax(logit.squeeze(),dim = 0) # Single image hence dim = 0, single prediction\n",
        "    pred_prob.append(label.cpu())\n",
        "pred_prob = torch.stack(pred_prob) # Turn list into tensor"
      ],
      "metadata": {
        "id": "u5qFjGfARbwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(pred_prob)"
      ],
      "metadata": {
        "id": "sgrCyEqK3pV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_prob[:2]"
      ],
      "metadata": {
        "id": "UXb4xwDt3yNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_class = pred_prob.argmax(dim = 1)\n",
        "pred_class # Probabilties to Labels"
      ],
      "metadata": {
        "id": "UkzuTM6k3dRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nrow = 5\n",
        "ncol = 1\n",
        "i = 0\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(0,nrow*ncol):\n",
        "  plt.subplot(nrow,ncol,i+1)\n",
        "  plt.axis(False)\n",
        "  plt.imshow(test_samples[i].squeeze())\n",
        "  if class_names[pred_class[i]] == class_names[test_labels[i]]:\n",
        "    plt.title(f\"Prediction: {class_names[pred_class[i]]} || True: {class_names[test_labels[i]]}\", c = \"green\",fontsize = 20)\n",
        "  else:\n",
        "    plt.title(f\"Prediction: {class_names[pred_class[i]]} || True: {class_names[test_labels[i]]}\", c = \"red\", fontsize = 20)\n"
      ],
      "metadata": {
        "id": "5kxjnhmi2TFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "c4vI6sNFRrMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See if torchmetrics exists, if not, install it\n",
        "try:\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
        "except:\n",
        "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")"
      ],
      "metadata": {
        "id": "aR2sWf8G8Fh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  for X,y in tqdm(test_DL, desc=\"--- MAKING PREDICTIONS ---\"):\n",
        "    X = X.to(\"cuda\")\n",
        "    y = y.to(\"cuda\")\n",
        "    logits = model(X)\n",
        "    pred = torch.softmax(logits,dim=1).argmax(dim=1) # Softmax dim = 1 because of batches\n",
        "    preds.append(pred.cpu())\n",
        "pred_ten = torch.cat(preds) # Concatenate list of predictions into a tensor\n",
        "len(pred_ten),pred_ten[:10]"
      ],
      "metadata": {
        "id": "YkIWXjmARvFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# Make Confusion matrix\n",
        "conf = ConfusionMatrix(num_classes=len(class_names),task=\"multiclass\")\n",
        "conf_tensor = conf(preds = pred_ten , target = test_data.targets)\n",
        "\n",
        "# Visualize\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_tensor.numpy(), # matplotlib likes working with NumPy\n",
        "    class_names=class_names, # turn the row and column labels into class names\n",
        "    figsize=(10, 7))"
      ],
      "metadata": {
        "id": "YkRJ-u2P_U3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Create a random tensor of shape [1, 3, 64, 64] and pass it through a nn.Conv2d() layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the kernel_size parameter goes up and down?"
      ],
      "metadata": {
        "id": "WppJnR1PRvwG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9CGyYUmBR0N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13. Use a model similar to the trained model_2 from this notebook to make predictions on the test torchvision.datasets.FashionMNIST dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualizing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "YHE9mUeIR0oV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "detDuZheR8XP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}